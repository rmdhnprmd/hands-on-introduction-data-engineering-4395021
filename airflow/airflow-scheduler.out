[2024-09-19T23:25:59.195+0000] {executor_loader.py:254} INFO - Loaded executor: SequentialExecutor
[2024-09-19T23:25:59.294+0000] {scheduler_job_runner.py:935} INFO - Starting the scheduler
[2024-09-19T23:25:59.295+0000] {scheduler_job_runner.py:942} INFO - Processing each file at most -1 times
[2024-09-19T23:25:59.309+0000] {manager.py:177} INFO - Launched DagFileProcessorManager with pid: 21755
[2024-09-19T23:25:59.311+0000] {scheduler_job_runner.py:1846} INFO - Adopting or resetting orphaned tasks for active dag runs
[2024-09-19T23:25:59.313+0000] {settings.py:63} INFO - Configured default timezone UTC
[2024-09-19T23:25:59.339+0000] {manager.py:409} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2024-09-19T23:26:47.304+0000] {scheduler_job_runner.py:423} INFO - 1 tasks up for execution:
	<TaskInstance: one_task_dag.one_task manual__2024-09-19T23:26:46.734156+00:00 [scheduled]>
[2024-09-19T23:26:47.305+0000] {scheduler_job_runner.py:495} INFO - DAG one_task_dag has 0/16 running and queued tasks
[2024-09-19T23:26:47.305+0000] {scheduler_job_runner.py:634} INFO - Setting the following tasks to queued state:
	<TaskInstance: one_task_dag.one_task manual__2024-09-19T23:26:46.734156+00:00 [scheduled]>
[2024-09-19T23:26:47.307+0000] {scheduler_job_runner.py:736} INFO - Trying to enqueue tasks: [<TaskInstance: one_task_dag.one_task manual__2024-09-19T23:26:46.734156+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
[2024-09-19T23:26:47.307+0000] {scheduler_job_runner.py:680} INFO - Sending TaskInstanceKey(dag_id='one_task_dag', task_id='one_task', run_id='manual__2024-09-19T23:26:46.734156+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
[2024-09-19T23:26:47.308+0000] {base_executor.py:168} INFO - Adding to queue: ['airflow', 'tasks', 'run', 'one_task_dag', 'one_task', 'manual__2024-09-19T23:26:46.734156+00:00', '--local', '--subdir', 'DAGS_FOLDER/one_task_dag.py']
[2024-09-19T23:26:47.357+0000] {sequential_executor.py:84} INFO - Executing command: ['airflow', 'tasks', 'run', 'one_task_dag', 'one_task', 'manual__2024-09-19T23:26:46.734156+00:00', '--local', '--subdir', 'DAGS_FOLDER/one_task_dag.py']
[2024-09-19T23:26:48.703+0000] {dagbag.py:587} INFO - Filling up the DagBag from /workspaces/hands-on-introduction-data-engineering-4395021/airflow/dags/one_task_dag.py
[2024-09-19T23:26:48.809+0000] {task_command.py:467} INFO - Running <TaskInstance: one_task_dag.one_task manual__2024-09-19T23:26:46.734156+00:00 [queued]> on host codespaces-af8981
[2024-09-19T23:26:49.493+0000] {scheduler_job_runner.py:764} INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='one_task_dag', task_id='one_task', run_id='manual__2024-09-19T23:26:46.734156+00:00', try_number=1, map_index=-1)
[2024-09-19T23:26:49.499+0000] {scheduler_job_runner.py:801} INFO - TaskInstance Finished: dag_id=one_task_dag, task_id=one_task, run_id=manual__2024-09-19T23:26:46.734156+00:00, map_index=-1, run_start_date=2024-09-19 23:26:48.874856+00:00, run_end_date=2024-09-19 23:26:49.180147+00:00, run_duration=0.305291, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=4, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-09-19 23:26:47.306203+00:00, queued_by_job_id=3, pid=22077
[2024-09-19T23:26:49.525+0000] {dagrun.py:854} INFO - Marking run <DagRun one_task_dag @ 2024-09-19 23:26:46.734156+00:00: manual__2024-09-19T23:26:46.734156+00:00, state:running, queued_at: 2024-09-19 23:26:46.789460+00:00. externally triggered: True> successful
[2024-09-19T23:26:49.526+0000] {dagrun.py:905} INFO - DagRun Finished: dag_id=one_task_dag, execution_date=2024-09-19 23:26:46.734156+00:00, run_id=manual__2024-09-19T23:26:46.734156+00:00, run_start_date=2024-09-19 23:26:47.149315+00:00, run_end_date=2024-09-19 23:26:49.526303+00:00, run_duration=2.376988, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-09-19 23:26:46.734156+00:00, data_interval_end=2024-09-19 23:26:46.734156+00:00, dag_hash=28eb05b3c92cd2209593441ade419476
